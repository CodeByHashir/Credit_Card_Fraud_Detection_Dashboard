{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d42fae0d",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection: End-to-End (Minimal)\n",
    "\n",
    "This notebook performs an end-to-end workflow on the classic creditcard.csv dataset, including:\n",
    "- Data loading and quick EDA\n",
    "- Minimal feature engineering\n",
    "- Statistical significance tests\n",
    "- Modeling with class imbalance handling (class weights vs SMOTE) and light tuning\n",
    "- Evaluation with ROC/PR curves, confusion matrix, and cost metric\n",
    "- SHAP-based explainability (global and local)\n",
    "\n",
    "Note: This is a minimal version designed to run quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9f1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, average_precision_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Imports ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset (expects creditcard.csv in the same folder)\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "print('Rows, Cols: ' + str(df.shape))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34013a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal Feature Engineering: add hour_of_day and day_of_week from Time as proxies\n",
    "# The dataset's Time is seconds from first transaction; we derive simple cyclical proxies\n",
    "df['hour_of_day'] = ((df['Time'] // 3600) % 24).astype(int)\n",
    "df['day_of_week'] = ((df['Time'] // 86400) % 7).astype(int)\n",
    "print(df[['Time','hour_of_day','day_of_week']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Tests: Compare Amount and hour_of_day by Class\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, chi2_contingency, kruskal\n",
    "fraud = df[df['Class'] == 1]\n",
    "nonfraud = df[df['Class'] == 0]\n",
    "tstat, tp = ttest_ind(fraud['Amount'], nonfraud['Amount'], equal_var=False)\n",
    "u, up = mannwhitneyu(fraud['Amount'], nonfraud['Amount'], alternative='two-sided')\n",
    "ct = pd.crosstab(df['hour_of_day'], df['Class'])\n",
    "chi2, chip, dof, exp = chi2_contingency(ct)\n",
    "kw, kwp = kruskal(df[df['Class']==0]['hour_of_day'], df[df['Class']==1]['hour_of_day'])\n",
    "print('Welch t-test p: ' + str(tp))\n",
    "print('Mann-Whitney p: ' + str(up))\n",
    "print('Chi-square p: ' + str(chip))\n",
    "print('Kruskal-Wallis p: ' + str(kwp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57687960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split (stratified)\n",
    "feature_cols = [c for c in df.columns if c != 'Class']\n",
    "X = df[feature_cols]\n",
    "y = df['Class'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print('Train/Test shapes: ' + str(X_train.shape) + ' ' + str(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models and light GridSearchCV using average_precision as scoring\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.array([0,1]), y=y_train)\n",
    "cw = {0: class_weights[0], 1: class_weights[1]}\n",
    "pipe_logit_w = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=200, solver='lbfgs', class_weight=cw, n_jobs=1))])\n",
    "pipe_rf_w = Pipeline([('clf', RandomForestClassifier(class_weight=cw, n_estimators=200, random_state=42, n_jobs=-1))])\n",
    "pipe_logit_sm = ImbPipeline([('scaler', StandardScaler()), ('smote', SMOTE(random_state=42)), ('clf', LogisticRegression(max_iter=200, solver='lbfgs', n_jobs=1))])\n",
    "pipe_rf_sm = ImbPipeline([('smote', SMOTE(random_state=42)), ('clf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1))])\n",
    "param_logit = {'clf__C': [0.1, 1.0, 10.0]}\n",
    "param_rf = {'clf__n_estimators': [200, 400], 'clf__max_depth': [None, 10], 'clf__min_samples_split': [2, 5]}\n",
    "from sklearn.metrics import make_scorer\n",
    "scoring = 'average_precision'\n",
    "def run_gs(name, est, grid):\n",
    "    gs = GridSearchCV(est, grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print(name + ' best params: ' + str(gs.best_params_))\n",
    "    return gs.best_estimator_\n",
    "best_logit_w = run_gs('LogReg_ClassWeight', pipe_logit_w, param_logit)\n",
    "best_rf_w = run_gs('RF_ClassWeight', pipe_rf_w, param_rf)\n",
    "best_logit_sm = run_gs('LogReg_SMOTE', pipe_logit_sm, param_logit)\n",
    "best_rf_sm = run_gs('RF_SMOTE', pipe_rf_sm, param_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530be16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models with multiple metrics and plots\n",
    "def evaluate(name, model, X_test, y_test):\n",
    "    proba = model.predict_proba(X_test)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, preds, average='binary', zero_division=0)\n",
    "    rocauc = roc_auc_score(y_test, proba)\n",
    "    ap = average_precision_score(y_test, proba)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    FP = int(cm[0,1]); FN = int(cm[1,0])\n",
    "    cost = 1 * FP + 10 * FN\n",
    "    print(name + ' metrics:')\n",
    "    print('Precision: ' + str(round(precision,4)))\n",
    "    print('Recall: ' + str(round(recall,4)))\n",
    "    print('F1: ' + str(round(f1,4)))\n",
    "    print('ROC-AUC: ' + str(round(rocauc,4)))\n",
    "    print('PR-AUC (AP): ' + str(round(ap,4)))\n",
    "    print('Confusion Matrix:')\n",
    "    print(cm)\n",
    "    print('Cost (FP=1, FN=10): ' + str(cost))\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    prec_c, rec_c, _ = precision_recall_curve(y_test, proba)\n",
    "    plt.style.use('default')\n",
    "    plt.rcParams['font.family'] = ['Inter']\n",
    "    plt.rcParams['font.sans-serif'] = ['Inter']\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "    ax.set_axisbelow(True)\n",
    "    for spine in ['top','right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.spines['left'].set_color('#171717')\n",
    "    ax.spines['bottom'].set_color('#171717')\n",
    "    ax.grid(axis='y', color='#F3F4F6')\n",
    "    ax.plot(fpr, tpr, color='#2563EB', label=name + ' ROC')\n",
    "    ax.plot([0,1],[0,1], color='#E5E7EB', linestyle='--', label='Random')\n",
    "    ax.set_title('ROC Curve - ' + name, fontsize=20, color='#171717', pad=15)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=16, color='#171717', labelpad=10)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=16, color='#171717', labelpad=10)\n",
    "    ax.tick_params(axis='both', labelsize=14, colors='#171717')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)\n",
    "    ax.set_axisbelow(True)\n",
    "    for spine in ['top','right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "    ax.spines['left'].set_color('#171717')\n",
    "    ax.spines['bottom'].set_color('#171717')\n",
    "    ax.grid(axis='y', color='#F3F4F6')\n",
    "    ax.plot(rec_c, prec_c, color='#24EB84', label=name + ' PR')\n",
    "    ax.set_title('Precision-Recall Curve - ' + name, fontsize=20, color='#171717', pad=15)\n",
    "    ax.set_xlabel('Recall', fontsize=16, color='#171717', labelpad=10)\n",
    "    ax.set_ylabel('Precision', fontsize=16, color='#171717', labelpad=10)\n",
    "    ax.tick_params(axis='both', labelsize=14, colors='#171717')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    return {'model': name, 'precision': precision, 'recall': recall, 'f1': f1, 'roc_auc': rocauc, 'avg_precision': ap, 'cost_FP1_FN10': cost}\n",
    "results = []\n",
    "results.append(evaluate('LogReg_ClassWeight', best_logit_w, X_test, y_test))\n",
    "results.append(evaluate('RF_ClassWeight', best_rf_w, X_test, y_test))\n",
    "results.append(evaluate('LogReg_SMOTE', best_logit_sm, X_test, y_test))\n",
    "results.append(evaluate('RF_SMOTE', best_rf_sm, X_test, y_test))\n",
    "results_df = pd.DataFrame(results).sort_values(['avg_precision','roc_auc','f1'], ascending=False)\n",
    "print('Results summary:')\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c547ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP explainability using the best model from results_df\n",
    "best_name = results_df.iloc[0]['model']\n",
    "print('Best model for SHAP: ' + str(best_name))\n",
    "model_map = {\n",
    "    'LogReg_ClassWeight': best_logit_w,\n",
    "    'RF_ClassWeight': best_rf_w,\n",
    "    'LogReg_SMOTE': best_logit_sm,\n",
    "    'RF_SMOTE': best_rf_sm\n",
    "}\n",
    "best_model = model_map[best_name]\n",
    "# For tree vs non-tree decide SHAP path\n",
    "clf = best_model.named_steps['clf'] if 'named_steps' in dir(best_model) else best_model.steps[-1][1]\n",
    "is_tree = ('RandomForestClassifier' in str(type(clf)))\n",
    "try:\n",
    "    if is_tree:\n",
    "        explainer = shap.TreeExplainer(clf)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        print('Computed Tree SHAP values')\n",
    "    else:\n",
    "        explainer = shap.Explainer(best_model.predict_proba, X_train, feature_names=X_train.columns.tolist())\n",
    "        shap_values = explainer(X_test)\n",
    "        print('Computed model-agnostic SHAP values')\n",
    "except Exception as e:\n",
    "    explainer = shap.Explainer(best_model.predict_proba, X_train, feature_names=X_train.columns.tolist())\n",
    "    shap_values = explainer(X_test)\n",
    "    print('Fallback to model-agnostic SHAP values')\n",
    "# Global importance (bar)\n",
    "plt.figure(figsize=(12,8))\n",
    "shap.summary_plot(shap_values if is_tree else shap_values[:,1], X_test, plot_type='bar', show=False)\n",
    "plt.title('Global Feature Importance (SHAP) - ' + str(best_name))\n",
    "plt.show()\n",
    "# Beeswarm for positive class\n",
    "plt.figure(figsize=(12,8))\n",
    "shap.summary_plot(shap_values[1] if is_tree else shap_values[:,1], X_test, show=False)\n",
    "plt.title('SHAP Summary (Fraud Class) - ' + str(best_name))\n",
    "plt.show()\n",
    "# Local explanations for a few fraud samples\n",
    "fraud_idx = y_test[y_test == 1].index[:3]\n",
    "for i in fraud_idx:\n",
    "    row_pos = X_test.index.get_loc(i)\n",
    "    if is_tree:\n",
    "        vals = shap_values[1][row_pos]\n",
    "        base = explainer.expected_value[1]\n",
    "    else:\n",
    "        vals = shap_values[row_pos,1].values\n",
    "        base = explainer.expected_value[1]\n",
    "    exp = shap.Explanation(values=vals, base_values=base, data=X_test.loc[i].values, feature_names=X_test.columns.tolist())\n",
    "    shap.plots.waterfall(exp, max_display=15, show=False)\n",
    "    plt.title('Local SHAP Waterfall - index ' + str(i))\n",
    "    plt.show()\n",
    "print('SHAP global and local explanations generated.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results summary\n",
    "results_df.to_csv('model_results_summary_minimal.csv', index=False)\n",
    "print('Saved model_results_summary_minimal.csv')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
